---
title: "Data Science for the Natural Environment (FA21)"
subtitle: "BI449 Data Science for the Natural Environment"
author: "Shannon J. O'Leary"
date: "`r Sys.Date()`"
knit: "bookdown::preview_chapter"
output:
  msmbstyle::msmb_html_book:
    highlight: tango
    toc: TRUE
    toc_depth: 1
    split_by: chapter
    margin_references: FALSE
    css: msmb.css
bibliography: labmanual.bib
link-citations: yes
editor_options: 
  chunk_output_type: inline
---

```{r include=FALSE}

library(msmbstyle)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, 
                      cache.extra = packageVersion('msmbstyle'),
                      warning = FALSE,
                      message = FALSE)


options(htmltools.dir.version = FALSE)

source("scr/ggplot.R")

```

# Exploratory Analysis

**Learning Objectives**

After completing this tutorial you should be able to

* identify specific steps to explore a new data set
* formulate a question and determine if your data set is appropriate to answer it
* refine questions based on data contained in a data set
* outline a strategy for data exploration using graphs

Download the [04_ExploratoryAnalysis](https://drive.google.com/drive/folders/18Sl718Ua5F_-UqHtzFgkMo5uo22Q_JJp?usp=sharing) project folder. Once you have downloaded it, unzip the project directory into your `BI449` directory. 

To get some practice setting up your own project files, you might notice that this one does not yet have an `Rproj` file or any `Rmarkdown` files in it. So the first thing we want to do is create a new R project. To do this open `Rstudio` then use the dropdown menu in the top right corner to select `New Project` and from there `New Project in an existing directory`. From there, navigate to and select the project create an R project.

Once you have created and opened the project you should see the project name in the top right corner per usual^[Pro tip: If you run into issues where an Rmarkdown won't render or file paths aren't working (especially if things were working previously) one of your first steps should be to double check that the correct `Rproj` is loaded.].

Open a new `Rmd` file using `File > New File > R Markdown` or the drop down menu of the green plus button below `File` and save it in your Visualization/Climate Change project directory. That's right - training wheels are off ... you will need to add all of your own headers, plain text etc. Set up the `YAML` header so that you are the author and when knitted the date will reflect the date of the creation of the document.

When you create a new `Rmarkdown` file, it loads a template, i.e. it shows you standard formatting options, it also means that you already have content so e.g. if you wanted to test out that you have your `YAML` header set up correctly or you are testing out a new theme, you could just knit the file and see what happens. Of course, since you are going to add your own content you should delete that automatically inserted content.

Now that you have some experience using `Rmarkdown` files to document your work in a reproducible way, you have probably started making a list of preferences (e.g. printing chunk out put in the console or in the document itself) and a list of things you find annoying. We have already seen a few options to customize individual code chunks by adding arguments between the curly brackets. `r` indicates the engine (coding language) and we've also inserted `fig.height` and `fig.width` to alter the plot size in the final knitted document.

You can also use the setup chunk to set global settings, i.e. set certain things once for the entire document. 

When you opened a new `Rmarkdown` file, you should have seen a code chunk in the very top that has been named `setup`^[you can name any code chunk by inserting a name right after indicating `r` as your engine. This can be helpful because you can use the navigation menu to navigate directly to a code chunk.`]); you will also see that it has the additional argument `include=FALSE` between the curly brackets. This means that when you knit your document, that code chunk will be run, but the code itself will not be visible in the knitted `html` document. 

In that code chunk you should see `knitr::opts_chunk$set(echo = TRUE)` - this is already setting a global format for all codes which is that when you knit the document it will print (echo) the code chunk itself and not just the output. You can add additional arguments e.g. `warning = FALSE`, `error = FALSE`, `message = FALSE` will turn off the messages, warnings and errors being printed out when knitting the document^[You will still see them in the console so you can still troubleshoot a needed, it just means you don't have it included in the outcome fo your document].

Remember, you should always check your `html` document after it knits to make sure that everything has converted as expected, including your figures, bullet points etc. 

Let's load our packages so we can get started. You will likely have to install `janitor` and `skimr` before you can load them^[Remember, you only have to do this once ... this is the type of thing where it is more convenient to run it directly in the console so it is not re-run every time you knit your document.]. 

```{r}

# load libraries
library(tidyverse)
library(skimr)
library(janitor)

library(knitr)

# turn of sci notation
options(scipen=999)

```


## Exploratory Analysis

The goal of exploratory analysis is systematic way of exploring data set primarily through visualizations. It generally is an iterative process that starts with a question or hypothesis. Most of your exploratory analysis consists of visualizing, transforming, and even modeling your data to answer that question. Finally, your would summarize your results and conclusions and use that to refine your original question or generate new questions. It frequently is the first step before deciding on what your formal analysis will look like and can serve to generate hypothesis for further exploration.

Part of exploratory analysis is quality control of your data, determining if it meets your expectations and cleaning it up as needed. Frequently it includes using the existing raw data to transform your data into parameters that are more useful for your assessment.


## Formulate a question

Recall, from our visualization of Climate Change indicators that we left the question of whether or not hurricanes are going "to get worse" unresolved even after comparing both changes in the number of names storms, major hurricanes, and the intensity.

Let's say we wanted to explore whether or not natural disasters have gotten worse as climate change has progressed. To do this we can turn to the [International Disaster Database](https://www.emdat.be/).

`r msmbstyle::question_begin(label = "ques:eda-1")`

Go to their website and use information you can find about the data collected to answer the following questions (use bullet points where appropriate):

1. How is (emergency) disaster defined?
2. What are the major classifications of natural disasters included in the data set?
3. Which of these categories do you think are most likely impacted by climate change?
4. What measures can you use to determine if natural disasters are "getting worse"? Should different categories have different measures?
5. What other mechanisms do you think could result in an increase in natural disasters?

`r msmbstyle::question_end()`


`r msmbstyle::question_begin(label = "ques:eda-2")`

"Are natural disasters getting worse" is a pretty general question. Based on your overview of what is in the data set, try to formulate three more specific questions that you could explore using this data set.

`r msmbstyle::question_end()`


## Read & Wrangle data set

You should have a copy of the tab-delimited file in your `data` folder. It contains an additional 6 lines at the top that have information on when and where it was downloaded.

```{r}

disaster <- read_delim("data/nat-disasters_emdat-query-2021-10-05.txt", delim = "\t", skip = 6)

```

Our first step always is to take a look at the data set and make sure that it has read in correctly (i.e. that the columns are correctly separated, numeric columns are numeric, character columns are characters etc.) and is in a usable format.

`r msmbstyle::question_begin(label = "ques:eda-3")`

Take a quick look at the data set using `View()` to make sure everything has read in correctly. Quickly skim to get an idea of how many columns/rows there are, how much missing data there is, that data types are correct etc.

`r msmbstyle::question_end()`

Even though data has read in correctly does not necessarily mean that it is in the most use-able format ... remember plotting and filtering data sets requires typing variable names in over and over again. Therefore, we want to make sure that everything is set up in a way where we will be able to avoid mistakes that are mostly due to typos.

For example, let's take a look at the column names:

```{r}

colnames(disaster)

```

Apparently, they have not read our guidelines for naming things. Column headers with special characters and spaces are super annoying, you might recall from our previous adventures in data wrangling that every time we want to call a column with spaces we are going to have to use back ticks to tell R that it isn't separate words but a single name.

Now is probably a good time to learn how to rename columns. The most straightforward way is using `rename()`.

Let's say we wanted to rename `Dis No` to `DisNo` the syntax is simple `NewName = OldName`.

```{r}

disaster %>%
  rename(DisNo = `Dis No`) %>%
  head()

```

This would be pretty annoying if we wanted to rename all of our columns by hand. 

Fortunately, we can leverage the function `janitor::clean_names()` function^[the notation format you see here specifies the `Rpackage` and then the function within it, as `package::function()`.] which is designed to parse letter cases and separators - the default is to convert it to `snake_case`, i.e. all names are lowercase and words are separated by an underscore, it also deals with duplicate names and special characters.

Let's see what this does for us:

```{r}

disaster <- read_delim("data/nat-disasters_emdat-query-2021-10-05.txt", delim = "\t", skip = 6) %>%
  clean_names()

head(disaster)

```

That looks much better. Similar to running `head()` to make sure the first set of lines has read in properly, running `tail()` gives you a quickly look at whether the end of the file read in correctly as well.


## Get an overview of the data set

Our next step always is to determine what information is contained in the data set and how it is organized. 

First, we will need to understand what information is contained in each column. Some of the column headers are more self-explanatory than others. One of the most helpful documents at this point is the metadata which will tell us what information is in each column. A good place to look for that is the [data portal](https://public.emdat.be) where you accessed the data set itself.

`r msmbstyle::question_begin(label = "ques:eda-4")`

Determine where you can find meta-data for our data set and describe what information is contained in the data set based on the included columns. Indicate which you think will be most useful to answer our general question based on your answers to Q1.

`r msmbstyle::question_end()`


Now, we can take a look at some of the specifics of how the information is organized in the data set and specifics on the information contained.

`r msmbstyle::question_begin(label = "ques:eda-5")`

Based on some of our previous exploits exploring data, come up with a checklist of at least five things to routinely check any time you are exploring a new data set, wherever possible include what function(s) you could use to look at that.

`r msmbstyle::question_end()`


`r msmbstyle::solution_begin()`

Factors to consider are among other things understanding how many rows/columns there are, what variables are included, whether it is in a tidy format or not, what data type each variable is, and what the range/distribution of values is.

You can get dimensions of the data set using `ncols()` and `nrows()`, `str()` will give you dimensions, the class, and data types (classes) of individual columns.

`r msmbstyle::solution_end()`

Another helpful functions is `skimr::skim()`

`r msmbstyle::question_begin(label = "ques:eda-6")`

Run the function on your data set and briefly describe what information you can get from it.

`r msmbstyle::question_end()`

```{r}

skim(disaster)


```

For numerical columns mean values and percentiles can give you an overview of how the data is distributed. However for columns that contain strings or characters we cannot produce those types of summary statistics. Rather, we are probably more interested on how many unique values those columns contain and what those unique entries are.

`skim()` already gave us the number of unique entries for each column, we have two options we can use to determine what those values are. The first is `unique()`. This function makes use of the fact that each column is a vector^[Remember, we can access each column of a dataframe as `df$columnname].

```{r}

unique(disaster$disaster_subgroup)

```
When you run this function it returns a vector; while this might be helpful in some contexts, it would be helpful if we could also view it in a tabular format. Do not fret - `tidyverse` got you.

```{r}

disaster %>%
  distinct(disaster_subgroup)

```

## Chose a question to explore

Frequently you will have a general question (which is why you pulled a data set in the first place); in this case "Are natural disasters getting worse with climate change?". 

There may be more than one way to go after that question ... and you might need some additional exploration of the data set to generate additional questions (hypothesis) and ultimately find the one you are mot interested in. 

In this case, we could focus on whether we are indeed observing an increase in frequency of events and/or we could compare if different groups of natural disasters that are more dependent on climate/weather conditions (storms, hurricanes) are increase more rapidly compared to categories that have other origins (e.g. earthquakes or volcanic eruptions). 

Or, we could have already done some analysis (or background reading) that indicates that natural disasters linked to climate patterns are indeed predicted to get worse based on modeling. In that case we might be more interested whether the impact of natural disasters on humans is getting increasingly worse. We could be at a point where at least some of the changes to the climate system are inevitable and in that case the question of mitigation of effects and preparedness like early warning systems or infrastructure become more important. We cannot stop the events from happening but to an extent we can control how well we can deal with them.

Exploratory Analysis is fundamentally a very creative process and thinking outside the box can be what sets your analysis apart from what everyone else is doing. However, before we can start thinking outside the box we need to first figure out what "the box is" and use that as our starting point. This does mean you should always start with the boring standard stuff, cover your bases and then from there work towards something more interesting - though sometimes the "boring" stuff is the most revealing!


## Plot the data!

While tables are sometimes more appropriate, most exploratory analysis involves generating plots that help you get an overview of the data in relation to your question.

`r msmbstyle::question_begin(label = "ques:eda-7")`

We should make a distinction between **exploratory figures** and **explanatory** or **final figures**. Briefly contrast the two in terms of their goal and audience and how this might be reflected in the presentation of the visualization.

`r msmbstyle::question_end()`

A good place to start is to get an idea of the **variation** or **variance** of the data you are interested in.

`r msmbstyle::question_begin(label = "ques:eda-8")`

List 3 - 5 ways that you can assess the variance of a measured value. What metrics can you calculate and what options do we have to visualize?

`r msmbstyle::question_end()`


`r msmbstyle::solution_begin()`

You can calculate summary statistics

* mean, median
* mininimum, maximum values (range)
* quantiles

(`fivenum()` will give you min, 25th percentile, median, 75th percentile, max)

To visualize

* barplots for categorical values
* histograms for continuous values (your individual bins essentially become components of a categorical value)
* boxplots to compare distributions of continuous values

For all of these assessments your should always ask the following questions

* Which values are more common than others? Why?
* Which values are more rare than others? Why?
* Are there distinct clusters that emerge?
* Do overall patterns meet my expectations?
* Are there patterns that stand out? Are they unusual/unexpected?

In each case, as you pick up patterns you want to also ask "why" questions ... those are the ones that will lead you to the next steps of your exploration.

Typically you will want to explore outlier values (are they true outliers or do they need to be removed?) and patterns of missing data (too much missing data and you might need to find a different data set)

`r msmbstyle::solution_end()`

Let's start by figuring out how many observations fall into each sub-category of natural disasters^[We finally get to see the alternative to `stat = "identity"` in using barplots! To plot distribution of categorical variable you are now telling `ggplot` to count the number of observations for each category].

```{r}

ggplot(disaster, aes(x = disaster_subgroup)) +
  geom_bar(stat = "count")

```
and we could do the same for our disaster types.

```{r}

ggplot(disaster, aes(x = disaster_type)) +
  geom_bar(stat = "count")


```

We probably want to be able to read those labels

```{r}

ggplot(disaster, aes(x = disaster_type)) +
  geom_bar(stat = "count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

This is giving us global numbers, we might want to break it up by region.

```{r fig.height=7}

ggplot(disaster, aes(x = disaster_type)) +
  geom_bar(stat = "count") +
  facet_wrap(. ~ region) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

If we want to think specifically about whether impact is increasing we should filter our data set to include only events for which damages where assessed.

Let's create new object with only those observations and then get an overview of distribution of the damage incurred.

```{r}

damages <- disaster %>%
  filter(!is.na(total_damages_000_us))


ggplot(damages, aes(x = total_damages_000_us)) +
  geom_histogram()

```

That looks like we might have some outliers that are skewing our histogram. We can try looking at e.g. a square root scale, which skews the y-axis in a systematic way^[This is the type of thing where in order to not be unintentionally mislead you would always want to add "Note, the skewed y-scale"].

```{r}

ggplot(damages, aes(x = total_damages_000_us)) +
  geom_histogram() +
  scale_y_sqrt()

```
Another way would be to set the binwidths manually, let's also divide our dollar amounts by 1,000,000 to make the x-axis more legible.

```{r}

ggplot(damages, aes(x = total_damages_000_us/1000000)) +
  geom_histogram(binwidth = 5)

```

Let's look at variation within different disaster types.

```{r}

ggplot(damages, aes(x = total_damages_000_us/1000000)) +
  geom_histogram(binwidth = 5) +
  facet_wrap(. ~ disaster_type)

```
It looks like we might want to limit our assessment to droughts, earthquakes, wildfires, floods, and storms. To make these comparisons if might be more helpful to switch to a boxplot.

```{r}

damages <- damages %>%
  filter(disaster_type %in% c("Drought", "Earthquake", "Flood", "Storm", "Wildfire"))

ggplot(damages, aes(x = disaster_type, y = total_damages_000_us/1000000)) +
  geom_boxplot()
  

```
We can also quickly calculate a set of summary stats for comparison

```{r}

damages %>%
  group_by(disaster_type) %>%
  summarize(mean = mean(total_damages_000_us)/1000000,
            sd = sd(total_damages_000_us)/1000000,
            min = min(total_damages_000_us)/1000000,
            max = max(total_damages_000_us)/1000000) %>%
  kable()

```

After you've explored patterns within variables you are interested in you are also going to want to explore relationships (**Covariation**) among variables^[Remember, when we start looking at correlation, we always need to be careful about how/when we infer causation!].

`r msmbstyle::question_begin(label = "ques:eda-9")`

List 3 - 5 ways that you can assess the covariance of a measured value.

`r msmbstyle::question_end()`


`r msmbstyle::solution_begin()`

You can calculate summary statistics and compare them, but for initial exploration of patterns visualizations are going to be much more handy.

You could create faceted barplot or have bars next to each other in a figure; faceted historgrams can be helpful too. But especially with increasing number of comparisons, one of the most straightforward ways to compare distributions are boxplots.

Comparing two categorical values can be challenging - heat plots can be used to visualize the number of observations that fulfill both categories, for two continuous values you can use scatter plots (though these become less useful with increasing number of observations in your data set).

`r msmbstyle::solution_end()`

We have already spent a little bit of time looking at more than one variable by looking at subgroups with in our data set, in this case the disaster types and regional differences. In our case the relationship we are really interested in is change over time. This means we are comparing two continuous values but it is a specific comparison we frequently describe as a time-series.

Let's take a look

```{r}

ggplot(damages, aes(x = year, y = total_damages_000_us/1000000)) +
  geom_point()

```
We could enhance this figure by e.g. color coding by disaster type.

```{r}

ggplot(damages, aes(x = year, y = total_damages_000_us/1000000, fill = disaster_type)) +
  geom_point(shape = 21)

```
Or we could color code by continent and make individual panels for different disaster types.

```{r}

ggplot(damages, aes(x = year, y = total_damages_000_us/1000000, color = continent)) +
  geom_point() +
  facet_wrap(. ~ disaster_type)

```
An alternative approach might be assess whether we are seeing changes in scale of each disaster and whether those show the same pattern as damages incurred, because the question we are really after is whether despite frequency and intensity increasing (or at least predicted to increase) that is also resulting in a scaling up of the damages.

Each of these has a different way of being measure so we will need to look at each disaster type in turn.

```{r}

damages %>%
  filter(disaster_type == "Storm") %>%
  ggplot(aes(x = dis_mag_value, y = total_damages_000_us/1000000, color = year)) +
  geom_point() +
  scale_color_viridis_c()

```
```{r}

damages %>%
  filter(disaster_type == "Flood") %>%
  ggplot(aes(x = dis_mag_value, y = total_damages_000_us/1000000, color = year)) +
  geom_point() +
  scale_color_viridis_b()

```
```{r}

damages %>%
  filter(disaster_type == "Earthquake") %>%
  ggplot(aes(x = dis_mag_value, y = total_damages_000_us/1000000)) +
  geom_point()

```
```{r}

damages %>%
  filter(disaster_type == "Drought") %>%
  ggplot(aes(x = dis_mag_value, y = total_damages_000_us/1000000)) +
  geom_point()

```
```{r}

damages %>%
  filter(disaster_type == "Wildfire") %>%
  ggplot(aes(x = dis_mag_value, y = total_damages_000_us/1000000)) +
  geom_point()

```

The final step is starting to ask whether patterns are specific to the data set or whether there are true non-random relationships between variables. Typical questions we might further explore at this point include e.g.

* Is this pattern due to random change or does the independent variable have significant explanatory power?
* How can the relationship implied by the pattern be described (e.g. linear regression)?
* How strong is the relationship (R2 value)?
* What other variables might affect or explain the relationship (e.g. are these variable correlated because they are both correlated to another variable that is responsible for the mechanism?)
* Does this relationship hold across subgroups of the relationship itself?

Fitting trend lines helps elucidate patterns (especially in time series). This is frequently where exploratory analysis transitions into a more formal analysis that involves statistical tests and fitting models. Keep in mind that we want to have a good grasp on whether our analysis is descriptive, inferential or causal/mechanistic in nature. Exploratory analysis is "quick and dirty", you are mainly focused on summarizing the data and highlighting broad-scale patterns that emerge. They are useful for assessing the quality of your data, eye-balling if patterns are what you expect (was your hypothesis correct(ish)), and getting and idea of what the next steps in a more formal analysis should be.

We could for example consider that we know have much better records in terms of when disasters occur and what the damages are and we may need to refine our analysis by limiting our data to a shorter time span. We might also want to determine if we see the same patterns for loss of life. Additionally, while we have played around with regional differences, that is also something to explore in light of expectations of e.g. better early warning systems and infrastructure in developed countries.

## Iterate your exploration

Now that we have an answer(ish) to our question - the first thing we should do is question our answer^[especially if your answer conforms to your *a priori* expectations!]. Always consider limitations of your data, whether there are alternative explanations, if your data has some inherent issues you need to be aware of etc. It can also be helpful to find at least one external data source to assess whether your answers are roughly in line with other (expected) measurements.

It is called an exploratory analysis for a reason, because it is just the beginning. Usually this is the beginning of a more sophisticated analysis. Important questions to ask always include

* Is your data appropriate for the question your are asking? 
* Do you need additional data to refine your answer?
* Do you have the right question or do you need to refine your question?

Exploratory Analysis frequently is more about hypothesis generating, rather than hypothesis testing. So you data exploration can be an important step to defining the precise (set of) question(s) you want to explore. Not infrequetly, the exploration of an intial question leads you to generating additional (perhaps more interesting) questions.


## Now you!

As you suspected, training wheels are coming off.

`r msmbstyle::question_begin(label = "ques:eda-10")`

Formulate three specific questions this data set can answer, consider that you have options like looking at specific geographic subsets, or different categories of natural disasters, you can also consider whether your would expect different types of natural disasters to show similar or different patterns.

Use headers, plain text, code chunks etc. as appropriate to write a mini report for each question - this should include stating your question as concisely as possible, exploratory figures, final explanatory figure, description & discussion of your results. Comment your code to generate your figures **line by line** with descriptive comments.

For each question, generate 3 - 5 exploratory figures that can help answer your question, these can include different visualizations of the same variables or different variables. In each case, chose the figure that summarizes your results best and refine your visualization so that it best summarizes your results, this includes a figure title, labeled axis, color choice, how data is encoded etc.

Write a figure legend that would accompany your figure in a report or paper, write a 3 - 5 sentence description of each figure (i.e. this should communicate the results with sufficient detail that somebody who *has not* seen the figure still fully understand them) and briefly discuss your results in 3-5 sentences in the context of the question you were asking (i.e. what are your conclusions, are there limitation to your data, alternative explanations, ...).

Chose one question + figure legend, description, and discussion and share it in our `#hwassignments` channel on slack.


`r msmbstyle::question_end()`


`r msmbstyle::question_begin(label = "ques:eda-11")`

Take a look your classmate's posts on slack, identify what you like about the visualization along with some **constructive** points for improvement. Getting feedback is really important. Our goal is clear communication; you have spent more time thinking about this question and the visualization so some things might be obvious to you that others might not catch right away, similar a set of colors might look good to you, but somebody else might struggle to tell things apart. The figure might be too busy etc. Sometimes it can also be helpful to have other people help you refine your question.

`r msmbstyle::question_end()`

