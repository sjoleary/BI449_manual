---
title: "Data Science for the Natural Environment (FA21)"
subtitle: "BI449 Data Science for the Natural Environment"
author: "Shannon J. O'Leary"
date: "`r Sys.Date()`"
knit: "bookdown::preview_chapter"
output:
  msmbstyle::msmb_html_book:
    highlight: tango
    toc: TRUE
    toc_depth: 1
    split_by: chapter
    margin_references: FALSE
    css: msmb.css
bibliography: labmanual.bib
link-citations: yes
editor_options: 
  chunk_output_type: console
---

```{r include=FALSE}

library(msmbstyle)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, 
                      cache.extra = packageVersion('msmbstyle'),
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE)


options(htmltools.dir.version = FALSE)

source("scr/ggplot.R")

theme_set(theme_standard)

```

# Remote Sensing

**Learning Objectives**

After completing this tutorial you should be able to

* understand the importance of long-term monitoring stations and baseline data
* understand how spatial and temporal patterns affect ecological processes
* describe what raster data sets are and how they encode spatial information
* read spatial raster data in R, making simple maps, and extracting information for non-spatial statistical tests.
* test whether plant growth (greenness & height) is drive more by elevation, slope, or aspect.
* consider large scale patterns of relationships between topography and vegetation

Download the [06_RemoteSensing](https://drive.google.com/drive/folders/1r2B4wa0hRGxK8aoNaoeQhULn3j2cFZNA?usp=sharing) project folder. Once you have downloaded it, unzip the project directory into your `BI449` directory.

Your first step is creating a new R project in your project folder. To do this open `Rstudio` then use the drop down menu in the top right corner to select `New Project` and from there `New Project in an existing directory`. From there, navigate to and select the project folder create an R project. Remember, your `Rproj` sets the working directory so you need to make sure that it is in your project folder.

Next, open a new `Rmd` file using `File > New File > R Markdown` or the drop down menu of the green plus button below `File` and save it in your Remote Sensing project directory. Use the setup chunk to set your global settings for the document using the options you've learned about in the last few projects. Remember, you should always check your `html` document after it knits to make sure that everything has converted as expected, including your figures, bullet points etc. We are going to need some specific packages for mapping; if you have not already you will need to install the following^[Remember, you only need to do this once, so you should type these functions directly into the console rather than have a code chunk which will try to run every time you knit the document.]

Before we start we need to install a few packages if you have not already. We will start with `Rcpp` - you likely already have this installed but you want to make sure you have the most uptodate version.

```{r eval=FALSE}

install.packages("Rcpp")
install.packages("rgdal")
install.packages("raster")
install.packages("sf")
install.packages("corrplot")

install.packages("rnaturalearthhires", 
                 repos = "http://packages.ropensci.org")

install.packages("ggspatial")

```

If you are on a Mac and it asks you to install from source, say no.

Let's load our packages so we can get started.

```{r}

# load libraries
library(plyr)
library(tidyverse)
library(janitor)
library(skimr)
library(glue)

library(knitr)

library(rgdal)
library(raster)
library(ggplot2)
library(viridisLite)
library(corrplot)
library(Hmisc)

library(sf)
library(ggspatial)
library(rnaturalearth)
library(rnaturalearthhires)
library(rnaturalearthdata)

# turn of sci notation
options(scipen=999)

```

## NEON & the power of longterm data sets

`r msmbstyle::question_begin(label = "ques:rem-1")`

Watch this [short introduction](https://www.youtube.com/watch?v=38JQXPubMoA) to the National Ecological Observatory Network (NEON) and read this [overview of the field stations and domains](https://www.neonscience.org/field-sites/about-field-sites) within the network of monitoring stations.

Briefly outline what NEON is, how it is designed, what data is being measured, what the central goal is, and how the design supports this mission.

Discuss the value of long-term monitoring stations and standardized data gathering.

`r msmbstyle::question_end()`


## Plot maps of topography and plants

The data set we are going to start out with is from a NEON station in the Sierra Nevada mountains in California from a region called [Soaproot Saddle](https://www.neonscience.org/field-sites/soap).

You already have several `*.tif` files in your data folder. These are `raster` data sets with information on NDVI and topology that were sampled for this NEON sites.

`r msmbstyle::question_begin(label = "ques:rem-2")`

Briefly describe how a raster data set encodes information.

`r msmbstyle::question_end()`

First we will load **Digital Terrain Model** data (DTM) which was obtained using LiDAR.

```{r}

dtm <- raster("data/NEON_D17_SOAP_DP3_298000_4100000_DTM.tif")

class(dtm)

```

`r msmbstyle::question_begin(label = "ques:rem-3")`

Briefly describe what data the terrain model raster data set contains.

`r msmbstyle::question_end()`

Next, we will read in the  **Digital Surface Model** LiDAR raster data set.

```{r}

dsm <- raster("data/NEON_D17_SOAP_DP3_298000_4100000_DSM.tif")

```

`r msmbstyle::question_begin(label = "ques:rem-4")`

Briefly describe what data the surface model raster data set contains.

`r msmbstyle::question_end()`

We already have information on elevation, but let's calculate slope and aspect as additional metrics to describe the topology. 

We will use degrees as a measure for slope based on the DTM raster data set.

```{r}

slope <- terrain(dtm, opt = "slope", unit = "degrees", neighbors = 8)

```

To determine aspect, we will calculate the "northness" as the cosine of aspect, which will read in radians^[Radian is the SI unit for measuring angles; it is a dimensionless value.].

```{r}

# calculate aspect
aspect <- terrain(dtm, opt = "aspect", unit = "radians", neighbors = 8)

# calculate northness
north <- cos(aspect)

```

This means that we can now describe the topography of the monitoring site using elevation, slope, and aspect.

Our overarching question is the extent to which topography impacts vegetation. We will use two variables to describe "levels of vegetation", first the Normalized difference vegetation index (NDVI) and second vegetation height.

Spectral imaging was used to determine the **Normalized Difference vegetation index** (NDVI) for our monitoring station.

```{r}

ndvi <- raster("data/NEON_D17_SOAP_DP3_298000_4100000_NDVI.tif")

```

`r msmbstyle::question_begin(label = "ques:rem-5")`

Describe what NDVI measures and how it can be used to assess vegetation.

`r msmbstyle::question_end()`

We can calculate the *vegetation height* as DSM - DTM.

```{r}

veg_ht <- dsm - dtm

```

Currently, we have several individual raster objects, each forming a different layer describing topography and vegetation for the same locations.

We can combine all these individual layers into a raster stack. This is a list, and each element is a different raster layer. Doing this has some advantages, for example, it is straight forward to make a single plot combining these different layers.


```{r}

# create raster stack
all_data <- stack(dtm, dsm, slope, north, ndvi, veg_ht)

# rename raster layers
names(all_data) <- c("DTM", "DSM", "slope", "north", "NDVI", "Vegetation.Height")

```

Now we can create maps for each of our raster files^[this may take a second to plot ... you are processing a bunch of data!]. We will use the function `plot()` instead of our usual `ggplot` options to keep it simple.

```{r}

plot(all_data, 
     col = viridis(255))

```

Let's consider what correlations we would expect to find based on these six maps.

`r msmbstyle::question_begin(label = "ques:rem-6")`

Argue whether overall you think that vegetation patterns are influenced by topography based on these maps and list anything noteworthy you have observed about these maps.

`r msmbstyle::question_end()`

`r msmbstyle::question_begin(label = "ques:rem-7")`

Argue which topographic metrics you think should have a strong association with NDVI and describe what you would expect that relationship to look like.

`r msmbstyle::question_end()`

`r msmbstyle::question_begin(label = "ques:rem-8")`

Argue which topographic metric you think should have a strong association with vegetation height and describe what you would expect that relationship to look like.

`r msmbstyle::question_end()`


## Explore relationships between topographic variable and vegetation patterns

First, lets convert our raster layers into data frames for easier use. We'll start by creating an empty data frame with as many rows as there are cells in our `raster` objects. Then we can use the function `extract()` the entire extent of the raster layer, i.e. we are pulling out all the information for each pixel and putting it into a set of columns[^3]. The `extent` argument, tells R to pull out all the information in the `raster` object^[Recall, each column of a `data.frame` is a vector].

```{r}

# create and empty data frame
df <- as.data.frame(matrix(NA, nrow = ncell(dtm), ncol=0))

# extract vegetation height
df$veg_ht <- raster::extract(veg_ht, extent(veg_ht))

# extract ndvi
df$ndvi <- raster::extract(ndvi, extent(ndvi))

# extract dtm
df$dtm  <- raster::extract(dtm, extent(dtm))

# extract slope
df$slope  <- raster::extract(slope, extent(slope))

# extract aspect
df$north <- raster::extract(north, extent(north)) 

head(df)

```

Note, that we no longer have spatial information (coordinates), however, values in the same row do correspond to the same pixel location in our raster object.

`r msmbstyle::question_begin(label = "ques:rem-9")`

Note, that some of the slope and north values are `NaN` - why do you think that is?

`r msmbstyle::question_end()`

Let's go ahead and remove those values.

```{r}

df <- df %>%
  filter(!is.na(slope)) %>%
  filter(!is.na(north))

head(df)

```

Because we have so much data, we will take a 1% subset of the data to decrease the computational power and time needed. 

Because our data set is so large (1 Million rows!), we would expect that a random subset is representative of the relationships as a whole.

`dplyr::slice_sample()` can be used to specify the proportion of rows that you would like to retain. The function will return a random sub sample.

```{r}

# set seed for reproducibility
set.seed(42)

# randomly select 1% of rows
df_sub <- df %>%
  slice_sample(prop = 0.01)

```

Now, let's take a look at the relationship between the vegetation and topographic variables. 

To do this efficiently using the `tidyverse` principles and some `ggplot` magic, need to pivot our data set. Ultimately, we want to have a data set with one column with our topography parameters, one with the topography measurements, one with vegetation variables and one with measurements; then we will be able to use `facet_grid()` to plot all combinations of variables.

```{r fig.cap="Relationship of topography and vegetation. Topography is described as elevation (dtm, in meters), northness (radians), and slope (degrees); vegetation is assessed using NDVI and vegetation height.", fig.width=9, fig.height=10}

df_plot <- df_sub %>%
  pivot_longer(names_to = "topog_param", values_to = "topog_meas", 3:5) %>%
  pivot_longer(names_to = "veget_param", values_to = "veget_meas", 1:2)

ggplot(df_plot, aes(x = topog_meas, y = veget_meas)) +
  geom_point(alpha = 0.25, size = .75) +
  facet_grid(veget_param ~ topog_param, scales = "free") +
  labs(x = "Topography", y = "Vegetation") +
  theme_facet

```

`r msmbstyle::question_begin(label = "ques:rem-10")`

Use the scatter plots to make predictions about statistical relationships. Consider whether any of these plots look like they are visualizing strong relationships.

Argue whether you think larger data sets make it easier or harder to identify distinct relationships "by eye".

`r msmbstyle::question_end()`

Let's determine whether these variables are correlated using the Pearson correlation coefficients. We can use ``Hmisc::rcorr`` to calculate all pairwise correlations and test whether the relationships are significant.

```{r}

P_corr <- rcorr(as.matrix(df), type="pearson")

```

The output is a list. Recall that we can access individual components of a list using `$`. In this case `P_corr$r` contains the correlation coefficients, and `P_corr$p` contains the p-values.

Visualizing correlations in a correlation plot can be helpful for a quick overview when you are working with a lot of different values, we can do this using the function `corrplot()`.

```{r fig.cap="Pairwise relationships of all topographical and vegetation variables measured using Pearson's correlation coefficient."}

corrplot(P_corr$r)

```

Alternatively, you can print the correlation coefficients as a matrix.

```{r}

P_corr$r

```

`r msmbstyle::question_begin(label = "ques:rem-11")`

Describe whether or not these relationships conform to your predictions when you looked at the maps and when you looked at the scatter plots and discuss what could be causing differences from your expectations.

`r msmbstyle::question_end()`

We can also print our p-values:

```{r}

P_corr$P

```

`r msmbstyle::question_begin(label = "ques:rem-12")`

Assess whether or not all of your relationships are statistically significant. Discuss the importance of p-values for large data sets.

`r msmbstyle::question_end()`

Let's coerce our correlation coefficients into something a bit more tidy, we'll also add the abbreviation for the site we've been looking at.

```{r}

tidy_cor <- as.data.frame(P_corr$r) %>%
  rownames_to_column("Param1") %>%
  pivot_longer(names_to = "Param2", values_to = "pearson", 2:6) %>%
  filter(Param1 %in% c("veg_ht", "ndvi")) %>%
  filter(!Param2 %in% c("veg_ht", "ndvi")) %>%
  mutate(Site = "SOAP")

```

Let's write that data frame out as a text file in our results folder.

```{r eval=FALSE}

write_delim(tidy_cor, "results/SOAP_correlation.txt", delim = "\t")

```


## Comparison of relationship of vegetation and topography across the US

Let's take a look at the different [NEON sites](https://www.neonscience.org/field-sites/explore-field-sites) across the US and choose locations from the contiguous 48.

We are going to come up with a sampling design to compare impact of topography on vegetation across domains and regions. We can access the elevetion and NDVI data sets from the [Data Portal](https://data.neonscience.org/data-products/explore).

`r msmbstyle::question_begin(label = "ques:rem-13")`

List the sites that were chosen and describe the sampling design behind using this specific set of locations.

`r msmbstyle::question_end()`

`r msmbstyle::question_begin(label = "ques:rem-14")`

Briefly describe what patterns you expect to see, consider e.g. whether you think that you will observe the same relationship across all locations. Look up the sites you have chosen to make informed predictions.

`r msmbstyle::question_end()`

`r msmbstyle::question_begin(label = "ques:rem-15")`

For your assigned sites go through the following process:

1.  read in the DTM, DSM, and NDVI `*tif` files as `raster` objects you downloaded from the data portal
2.  Calculate vegetation height, slope, and northness and create a raster stack to plot the six panel plot.
3.  Based on your plots predict which relationship you think will have a stronger association with vegetation height, determine if vegetation patterns overall appear to be influenced by topography, and note any other observations for this set of maps on their own and in relation to the California set.
4.  convert your raster table to a data.frame and take a 1% subset.
5.  plot the correlations between vegetation and topographic variables.
6.  calculate the correlations.
7.  convert your results into a tidy data set and add the location abbreviation.
8.  write your results into a text file.
9.  Briefly summarize your key results (what are the most significant relationships at the site you explored? Which don't seem to be important)

Share your correlation results (text file) in the `#hwassignments` channel on slack.

`r msmbstyle::question_end()`

We will compile all of the results into a map, so you can see how the impact of topographic variables varies across our studies locations.

First, let's read in a text file that has all the NEON sites and information on their geographic location. We are only interested in sites from the contiguous 48 so we will remove locations in Alaska, Hawaii, and Puerto Rico.

```{r}

sites <- read_delim("data/neon_sites.txt", delim = "\t") %>%
  clean_names() %>%
  separate(site_type, into = c("tmp", "site_cat"), sep = " ", remove = FALSE) %>%
  dplyr::select(-tmp) %>%
  filter(!state %in% c("AK", "HI", "PR"))

head(sites)

```

Let's start simple by creating a map that has all of our NEON sites on it.

First, we need to get a shapefile that we will use as our basemap - because we are going to want to orient ourselves within the US, we will also pull information we can use to plot state lines.

```{r}

world <- ne_countries(scale = "medium", returnclass = "sf")

us_states <- ne_states(country = "United States of America", returnclass = "sf")

```

We are not going to want to plot the entire world, so let's identify the lat/longs for the four corners of the box we want to plot but pulling information on the minimum and maximum latitude & longitude of our NEON sites and then adding a small buffer around it.

Then we can plot our map.

```{r fig.cap="NEON sites in contiguous US"}

# lat/long for map extend
x_min <- min(sites$longitude) - 2
x_max <- max(sites$longitude) + 2
y_min <- min(sites$latitude) - 2
y_max <- max(sites$latitude) + 2

# set font sizes for text labels
site_size <- 2

# set color for fill
map_color <- "#a8d481"

# create plot
ggplot() +
  geom_sf(data = world, color = "black", fill = map_color) +  # plot outline of countries
  geom_sf(data = us_states, color = "black", fill = NA) +     # plot outline of states
  coord_sf(xlim = c(x_min, x_max),
           ylim = c(y_min, y_max)) +                          # plot boundaries for map
  geom_text(data = sites, aes(x = longitude, y = latitude,    # add sites as labels
                              label = site_id, color = site_cat),
            size = site_size) +
  scale_color_manual(values = c("darkblue", "darkred"))

```

NEON sites are intentionally designed so aquatic and terrestrial sites are ideally right next to each other, so those are plotting right on top of each other.

Instead of the site id's we could also make the same map with points for locations.

```{r fig.cap="NEON site locations"}

# create plot
ggplot() +
  geom_sf(data = world, color = "black", fill = map_color) +  # plot outline of countries
  geom_sf(data = us_states, color = "black", fill = NA) +     # plot outline of states
  coord_sf(xlim = c(x_min, x_max),
           ylim = c(y_min, y_max)) +                          # plot boundaries for map
  geom_point(data = sites, aes(x = longitude, y = latitude,   # add sites as labels
                              fill = site_cat),
             shape = 21, size = 2, alpha = 0.5) +
  scale_fill_manual(values = c("darkblue", "darkred"))

```

If we want to compare differences in the relationships of topographic variables across all the sites we plotted, we could use the same method to plot the correlation coefficients, in addition to the site labels; all we need to do is add the correlation coefficients into our `sites` data.frame^[Once we have information for multiple sites, you will need to either read in all the text files with results and use `bind_rows` to create a single `data.frame`, or we will also allow for some outside R action, where you just cut and paste them all into a single text file and read that in.].

Here is how you can read in all your files and combine them into a single `data.frame`. We will create an empty list and then fill it with individual data.frames (one for each site) by looping over a vectory with all the filenames. Because we names our correlations files in a very standardized way, we can specify a pattern, and `R` will create a vector with all those filenames in the `results` folder for us.

```{r}

# path to results
path <- "results"

# pattern for filenames
pattern <- "correlation"

# list with all txt files in data directory
list.filenames <- list.files(path = path,
                             pattern = pattern)

# empty list to load files into
list.data <- list()

# loop to read in data files
for (i in list.filenames){
  
  file <- as.character(glue("{path}/{i}"))
  
  list.data[[i]] <- read_delim(file, delim = "\t")
  
}

correl_all <- ldply(list.data, data.frame) %>%
  dplyr::select(-`.id`)

# # write to file
# write_delim(correl_all, "results/Comp_pearson.txt", delim = "\t")

```

For example, we could create a map for slope and NDVI like this:

```{r fig.cap="Pearson correlation coefficient for slope and NDVI for all assessed sites"}

# add correlation coefficients
sites_pears <- sites %>%
  left_join(correl_all, by = c("site_id" = "Site")) %>%
  filter(!is.na(pearson)) %>%                          # retain only sites with pearson coefficient estimated
  filter(Param1 == "ndvi" & Param2 == "slope")         # choose veg & topog relationship to map


# set font sizes for text labels
site_size <- 4
cor_size <- 5

# create plot
ggplot() +
  geom_sf(data = world, color = "black", fill = map_color) +  # plot outline of countries
  geom_sf(data = us_states, color = "black", fill = NA) +     # plot outline of states
  coord_sf(xlim = c(x_min, x_max),
           ylim = c(y_min, y_max)) +                          # plot boundaries for map
  geom_text(data = sites_pears, aes(x = longitude, y = latitude,    # add sites as labels
                              label = site_id),
            size = site_size, color = "black") +
  geom_text(data = sites_pears, aes(x = longitude, y = latitude,    # add pearson coefficient as labels
                              label = round(pearson, digits = 2)),
            size = cor_size, color = "darkred", nudge_y = -1.5) +   # shift label below actual coordinates
  theme(legend.position = "none")

```


`r msmbstyle::question_begin(label = "ques:rem-16")`

Choose either NDVI or vegetation height and make a map showing the correlation coefficients for all sites that were compared for elevation, slope, and northness. Make sure your maps have titles, and that all the site names and correlation coefficients are legible in your map. Use `fig.height` and `fig.width` to adjust the size of your figures in your html document that you submit.

Compare the overall patterns of correlation across the United States and discuss your results - speculate on how these topographic parameters could be playing a role in differences in vegetation in different eco-domains across the United States.

`r msmbstyle::question_end()`






</br>

</br>

</br>

</br>

## Acknowledgments

These activities are based on the EDDIE Remote Sensing module.^[Dahlin, K. M. (2021). Remote Sensing of Plants and Topography in R (Project EDDIE).]

